# parameters related to parallel run
mpi_tasks: 0  # this controls the number of MPI tasks to be used on a cluster
openmp_threads: 8  # this controls the number of OpenMP threads to be used during execution

# paths to the code executables. If the codes are not installed, just leave the field empty.
executables:
  mcnp: path/to/mcnp6/executable  # it can also be just 'mcnp6' if the executable is in the PATH
  openmc:  path/to/openmc/executable  # idem
  serpent: path/to/serpent/executable  # idem
  d1s: path/to/d1s/executable  # idem

# run mode is either "local", "job" or "global_job"
# local: the code will be run locally on the machine where JADE is running
# job: the code will be submitted as a job to a cluster. Each simulation will be sent as a separate job
# global_job: the code will be submitted as a job to a cluster but all simulations will be sent as a single job
run_mode: local
# scheduler command (needed only if run_mode is "job" or "global_job")
scheduler_command: sbatch  # e.g. 'sbatch' for slurm, 'qsub' for torque, 'bsub' for lsf

# You can either modify the files or provide your own
# path can be expressed as relative to cfg/exe_config or absolute
# These templates are used for submission in cluster
code_job_template:
  mcnp: mcnp_template.sh
  openmc: openmc_template.sh
  serpent: serpent_template.sh
  d1s: d1s_template.sh
# Optional prefix to be added before the executable command
exe_prefix: srun  # e.g. 'srun' or 'aprun' or 'ibrun' or 'mpirun' depending on the system